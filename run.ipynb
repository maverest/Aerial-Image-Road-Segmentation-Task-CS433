{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mverest/Desktop/clean_ML_repo/code\n"
     ]
    }
   ],
   "source": [
    "%cd code\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from my_dataset import TestDataset\n",
    "from model import AttU_Net\n",
    "from model import init_weights\n",
    "from mask_to_submission import masks_to_submission\n",
    "import train_helpers as th\n",
    "\n",
    "\n",
    "%run -i my_dataset.py\n",
    "%run -i model.py\n",
    "%run -i train_helpers.py\n",
    "%run -i mask_to_submission.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_DIR = \"Data/test_set_images\"\n",
    "MODEL_PATH = \"saved_models\\VBest_best.pth\"\n",
    "THRESHOLD = 0.5\n",
    "TEST_IMG_DIR = \"predictions\"\n",
    "SUBMISSION_FILE_NAME = 'Best_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(mean=[0.0, 0.0, 0.0], \n",
    "                std=[1.0, 1.0, 1.0], \n",
    "                max_pixel_value=255.0),\n",
    "    ToTensorV2(),\n",
    "                ])\n",
    "\n",
    "test_dataset = TestDataset(root_dir=TEST_IMG_DIR, \n",
    "                           transform=test_transform, \n",
    "                           patch_size= None, \n",
    "                           stride= None, \n",
    "                           CLAHE= True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         shuffle=False,\n",
    "                         batch_size=1)\n",
    "\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AttU_Net().to(device)\n",
    "init_weights(model, init_type='kaiming', gain=0.02)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "\n",
    "predicted_mask = th.prediction_on_test_set(model=model, test_loader=test_loader, device=device, threshold=THRESHOLD, )\n",
    "\n",
    "\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = os.path.join(TEST_IMG_DIR,f\"test_{i}_mask\" + '.png')\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "masks_to_submission(SUBMISSION_FILE_NAME, *image_filenames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
